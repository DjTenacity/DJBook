# 系统学习-算法(一)

## 复杂度分析（上）

### 如何分析、统计算法的执行效率和资源消耗？

 数据结构和算法本身解决的是“快”和“省”的问题 

 执行效率是算法一个非常重要的考量指标 

 **复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半** 



 **1. 测试结果非常依赖测试环境** 

 **2. 测试结果受数据规模的影响很大** 

 **我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法**。 

### 大 O 复杂度表示法

 从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：**读数据**-**运算**-**写数据** , 假设每行代码执行的时间都一样，为 unit_time。 

```java
 int cal(int n) {
   //start___1 这三行每行都需要1 单位时间   3
   int sum = 0;   
   int i = 1;
   int j = 1;
   //end_____1 
     //start___2  这两行,每个都是 n 单位时间   2n
   for (; i <= n; ++i) {
     j = 1;
     //end_____2 
       //start___3  这两行,每个都是 n 单位时间,但是执行了n遍  [(n+n) * n]
     for (; j <= n; ++j) {
       sum = sum +  i * j;
        //start___3 
     }
   }
 }
```

 整段代码总的执行时间 T(n) =  [(n+n) * n  +2n+3 ] *unit_time。 

 **所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比**。

 

## T(n)=O(f(n))

+  T(n)  表示代码执行的时间 
+  n 表示数据规模的大小；
+ f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。
+ 公式中的 O，表示代码的执行时间 
+  T(n) 与 f(n) 表达式成正比。 

 所以   T(n) = O(2n*n+2n+3) 

 这就是**大 O 时间复杂度表示法**。

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度**（asymptotic time complexity），简称**时间复杂度**。 

 公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n2)。 

##  如何分析一段代码的时间复杂度？ 

 **1. 只关注循环执行次数最多的一段代码** 

 大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，**我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了**。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。 



 **2. 加法法则：总复杂度等于量级最大的那段代码的复杂度** 

 **3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积** 

![](D:\DJGitBook\数据结构与算法\img\复杂度量级.jpg)



 对于刚罗列的复杂度量级，我们可以粗略地分为两类，**多项式量级**和**非多项式量级**。其中，非多项式量级只有两个：O(2n) 和 O(n!)。 

 当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。 



 **1. O(1)** 

 **一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)**。 

 **2. O(logn)、O(nlogn)** 

